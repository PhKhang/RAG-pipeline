{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f17d6f7",
   "metadata": {},
   "source": [
    "## Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b51591",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -q weaviate-client sentence-transformers pyvi pymupdf langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5a85c2",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## Connecting to Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e21ad27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "\n",
    "client = weaviate.connect_to_local(\"localhost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bda436c",
   "metadata": {},
   "source": [
    "### Create Document Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dede28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.config import Configure, Property, DataType\n",
    "try:\n",
    "    client.collections.create(\n",
    "        name=\"Document\",\n",
    "        vectorizer_config=Configure.Vectorizer.none(),\n",
    "        properties=[Property(name=\"text\", data_type=DataType.TEXT)],\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error creating collection: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9144f3b8",
   "metadata": {},
   "source": [
    "### Closing the connection (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51fad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6d0fc4",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55f1137",
   "metadata": {},
   "source": [
    "### Test to check the distance of tokenized and non-tokenized (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a9a3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pyvi.ViTokenizer import tokenize\n",
    "\n",
    "\n",
    "# model = SentenceTransformer('dangvantuan/vietnamese-embedding')\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "raw = \"Hà Nội là thủ đô của Việt Nam\"\n",
    "tokenized = \"Hà_Nội là thủ_đô của Việt_Nam\"\n",
    "\n",
    "vec1 = model.encode(raw)\n",
    "vec2 = model.encode(tokenized)\n",
    "\n",
    "cos_sim = dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
    "print(f\"Cosine similarity between raw and tokenized: {cos_sim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab83b2c",
   "metadata": {},
   "source": [
    "### Embedding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33d72af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# model = SentenceTransformer('dangvantuan/vietnamese-embedding')\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52317afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def embed(text) -> List[List[float]]:\n",
    "    return model.encode(text).tolist()\n",
    "\n",
    "def import_texts_and_embeds_to_db(texts: List[str], embeddings: List[List],collection_name=\"Document\"):\n",
    "    for text, embedding in zip(texts, embeddings):\n",
    "        client.collections.get(collection_name).data.insert(\n",
    "            properties={\"text\": text}, vector=embedding\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233f5546",
   "metadata": {},
   "source": [
    "### Clear Document Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b0528b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_document_collection():\n",
    "    client.collections.delete(\"Document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc60f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clear_document_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bfe340",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a581b393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.query import MetadataQuery\n",
    "\n",
    "query = \"Tinh thể?\"\n",
    "query_tokenized = tokenize(query)\n",
    "query_vector = model.encode(query_tokenized).tolist()\n",
    "\n",
    "result = client.collections.get(\"Document\").query.near_vector(\n",
    "    near_vector=query_vector,\n",
    "    limit=5,\n",
    "    return_metadata=MetadataQuery(distance=True)\n",
    ")\n",
    "\n",
    "retrieved_objects = [obj for obj in result.objects]\n",
    "\n",
    "print(\"Query results:\")\n",
    "for i, obj in enumerate(retrieved_objects, 1):\n",
    "    print(f\"{i}. Dist: {obj.metadata.distance} - {obj.properties['text'][:140]}...\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53d9ce9",
   "metadata": {},
   "source": [
    "## PDF to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aef09b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"test-pdf/OS_C4_File and Disk management.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54594003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pymupdf\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "def pdf_to_raw_doc(file_name) -> List[Document]:\n",
    "    doc = pymupdf.open(file_name)\n",
    "    pages: List[Document] = []\n",
    "    for pg_num, page in enumerate(doc, start=1):\n",
    "        pages.append(\n",
    "            Document(\n",
    "                page_content=page.get_text(\"text\"),\n",
    "                metadata={\"source\": file_name, \"page\": pg_num},\n",
    "            )\n",
    "        )\n",
    "    return pages\n",
    "\n",
    "\n",
    "def split_doc(doc: Document, chunk_size: int, chunk_overlap: int) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Splits a Document into smaller chunks based on the specified chunk size and overlap.\n",
    "    \"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    )\n",
    "\n",
    "    page_contents = splitter.split_text(doc.page_content)\n",
    "\n",
    "    splitted_docs: List[Document] = []\n",
    "    for i, page_content in enumerate(page_contents):\n",
    "        splitted_docs.extend(\n",
    "            Document(\n",
    "                page_content=page_content,\n",
    "                metadata={\n",
    "                    \"source\": doc.metadata.get(\"source\", \"\"),\n",
    "                    \"page\": doc.metadata.get(\"page\", 1),\n",
    "                    \"chunk_index\": i,\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return splitted_docs\n",
    "\n",
    "\n",
    "def save_to_json(data, output_file):\n",
    "    \"\"\"Save the processed data to a JSON file.\"\"\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "def docs_to_json(docs: List[Document]) -> dict:\n",
    "    \"\"\"\n",
    "    Including preprocessing and chunking.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        {\n",
    "            \"source\": doc.metadata.get(\"source\", \"\"),\n",
    "            \"page\": doc.metadata.get(\"page\", 1),\n",
    "            \"chunk_index\": doc.metadata.get(\"chunk_index\", 0),\n",
    "            \"content\": doc.page_content,\n",
    "        }\n",
    "        for doc in docs\n",
    "    ]\n",
    "\n",
    "\n",
    "def json_to_docs(file_name: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Load documents from a JSON file.\n",
    "    \"\"\"\n",
    "    with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return [\n",
    "        Document(\n",
    "            page_content=item[\"content\"],\n",
    "            metadata={\n",
    "                \"source\": item.get(\"source\", \"\"),\n",
    "                \"page\": item.get(\"page\", 1),\n",
    "                \"chunk_index\": item.get(\"chunk_index\", None),\n",
    "            },\n",
    "        )\n",
    "        for item in data\n",
    "    ]\n",
    "\n",
    "\n",
    "def docs_to_strings(docs: List[Document]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Convert a list of Document objects to a list of strings.\n",
    "    \"\"\"\n",
    "    return [str(doc) for doc in docs]\n",
    "\n",
    "\n",
    "raw_docs = pdf_to_raw_doc(file_name)\n",
    "processed_docs: List[Document] = []\n",
    "for doc in raw_docs:\n",
    "    if len(doc.page_content) > 800:\n",
    "        print(\"Split\")\n",
    "        sub_docs = split_doc(doc, chunk_size=800, chunk_overlap=100)\n",
    "        processed_docs.extend(sub_docs)\n",
    "    else:\n",
    "        processed_docs.append(doc)\n",
    "\n",
    "json_docs = docs_to_json(processed_docs)\n",
    "save_to_json(json_docs, \"json/raw_docs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e76c251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embed(docs_to_strings(processed_docs))\n",
    "import_texts_and_embeds_to_db(\n",
    "    docs_to_strings(processed_docs), embeddings, collection_name=\"Document\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0ef9503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.query import MetadataQuery\n",
    "\n",
    "query = \"Scheduling?\"\n",
    "# query_tokenized = tokenize(query)\n",
    "query_vector = model.encode(query).tolist()\n",
    "\n",
    "result = client.collections.get(\"Document\").query.near_vector(\n",
    "    near_vector=query_vector,\n",
    "    limit=5,\n",
    "    return_metadata=MetadataQuery(distance=True)\n",
    ")\n",
    "\n",
    "retrieved_objects = [obj for obj in result.objects]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50d4014f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query results:\n",
      "1. Dist: 0.5142076015472412:\n",
      " page_content='Disk Scheduling\n",
      "Disk Storage |  Disk Scheduling Algorithms\n",
      "5 3\n",
      "• Disk Scheduling Algorithms\n",
      "ü FCFS (First-Come First-Served)\n",
      "ü SSTF (Shortest Seek Time First)\n",
      "ü SCAN (Elevator Algorithm)\n",
      "ü C-SCAN (Circular SCAN)\n",
      "ü LOOK (an optimized version of SCAN)\n",
      "ü C-LOOK (Circular LOOK)\n",
      "' metadata={'source': 'test-pdf/OS_C4_File and Disk management.pdf', 'page': 53}...\n",
      "2. Dist: 0.5761232972145081:\n",
      " page_content='Disk Access Time\n",
      "Disk Storage |  Disk Scheduling Algorithms\n",
      "5 2\n",
      "Disk Access Time = Seek Time + Rotational Time + Data Transfer Time\n",
      "Time to move \n",
      "Read/Write Head to the \n",
      "desired track/cylinder\n",
      "Time to rotate the \n",
      "desired sector to the \n",
      "Read/Write Head\n",
      "Time to transfer data from the disk\n",
      "Most dominant\n",
      "= Transferred Data/Transfer Rate\n",
      "' metadata={'source': 'test-pdf/OS_C4_File and Disk management.pdf', 'page': 52}...\n",
      "3. Dist: 0.5768440365791321:\n",
      " page_content='SSTF (Shortest Seek Time First)\n",
      "Disk Storage |  Disk Scheduling Algorithms\n",
      "5 5\n",
      "Disk requests: 13, 2, 38, 17, 36, 7, 21\n",
      "Current position \n",
      "of  R/W head\n",
      "No. track movement = (21-11) + (21-2) + (38-2) = 65\n",
      "' metadata={'source': 'test-pdf/OS_C4_File and Disk management.pdf', 'page': 55}...\n",
      "4. Dist: 0.6119112372398376:\n",
      " page_content='FCFS (First-Come First-Served)\n",
      "Disk Storage |  Disk Scheduling Algorithms\n",
      "5 4\n",
      "Current position \n",
      "of  R/W head\n",
      "Disk requests: 13, 2, 38, 17, 36, 7, 21\n",
      "No. track movement = (13-11) + (13-2) + (38-2) + (38-17) + \n",
      "(36-17) + (36-7) + (21-7) = 132\n",
      "' metadata={'source': 'test-pdf/OS_C4_File and Disk management.pdf', 'page': 54}...\n",
      "5. Dist: 0.6238189935684204:\n",
      " page_content='C-LOOK\n",
      "Disk Storage |  Disk Scheduling Algorithms\n",
      "5 9\n",
      "Disk requests: 13, 2, 38, 17, 36, 7, 21\n",
      "Current position \n",
      "of  R/W head\n",
      "No. track movement = (38-11) + (38-2) + (7-2) = 68\n",
      "' metadata={'source': 'test-pdf/OS_C4_File and Disk management.pdf', 'page': 59}...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Query results:\")\n",
    "for i, obj in enumerate(retrieved_objects, 1):\n",
    "    print(f\"{i}. Dist: {obj.metadata.distance}:\\n {obj.properties['text'][:]}...\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb5609d",
   "metadata": {},
   "source": [
    "### Check Document Collection size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e834e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear_document_collection()\n",
    "client.collections.get(\"Document\").aggregate.over_all(total_count=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c7211e",
   "metadata": {},
   "source": [
    "## LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8ba6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e175986",
   "metadata": {},
   "source": [
    "### The Thinker - Reasoning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae449ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENROUTER_DEEPSEEK_KEY\")\n",
    "\n",
    "llm_client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "stream = llm_client.chat.completions.create(\n",
    "    model=\"deepseek/deepseek-r1:free\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the meaning of life? Make it short.\"}],\n",
    "    extra_body={\"include_reasoning\": True},\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    if chunk.choices and getattr(chunk.choices[0].delta, \"reasoning\", None):\n",
    "        print(chunk.choices[0].delta.reasoning, end=\"\", flush=True)\n",
    "    if chunk.choices and chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404012b7",
   "metadata": {},
   "source": [
    "### The Finder - Retrieval Augmented Generation (RAG) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df372fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The meaning of life is subjective and can vary greatly among individuals, cultures, and beliefs. However, one common interpretation is that life's meaning emerges through personal growth, relationships, love, discovery, and contributions to the betterment of oneself and the world around you. Ultimately, your unique journey helps shape your perspective on the meaning of your life."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENROTER_MISTRAL_7B_KEY\")\n",
    "\n",
    "llm_client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "stream = llm_client.chat.completions.create(\n",
    "    model=\"mistralai/mistral-7b-instruct:free\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the meaning of life? Make it short.\"}],\n",
    "    # extra_body={\"include_reasoning\": True}, # No reason to add it because it is not supported\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    if chunk.choices and getattr(chunk.choices[0].delta, \"reasoning\", None):\n",
    "        print(chunk.choices[0].delta.reasoning, end=\"\", flush=True)\n",
    "    if chunk.choices and chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2815aa4c",
   "metadata": {},
   "source": [
    "### Check LLM API limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ac75d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "api_key = os.getenv(\"OPENROTER_MISTRAL_7B_KEY\")\n",
    "api_key = os.getenv(\"OPENROUTER_DEEPSEEK_KEY\")\n",
    "\n",
    "response = requests.get(\n",
    "  url=\"https://openrouter.ai/api/v1/auth/key\",\n",
    "  headers={\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "  }\n",
    ")\n",
    "\n",
    "print(json.dumps(response.json(), indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5801d8aa",
   "metadata": {},
   "source": [
    "## RAG pipeline integration with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "36a7a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_with_rag(query: str, llm_client: OpenAI = None):\n",
    "    if llm_client is None:\n",
    "        return \"LLM client is not provided.\"\n",
    "        \n",
    "    query_embed = embed([query])[0]\n",
    "    result = client.collections.get(\"Document\").query.near_vector(\n",
    "        near_vector=query_embed, limit=5, return_metadata=MetadataQuery(distance=True)\n",
    "    )\n",
    "\n",
    "    retrieved_objects = [obj for obj in result.objects]\n",
    "    retrived_texts = [\n",
    "        f\"Rank {i}. Dist: {obj.metadata.distance}:\\n {obj.properties['text'][:]}...\"\n",
    "        for i, obj in enumerate(retrieved_objects, 1)\n",
    "    ]\n",
    "    processed_retrived_text = \"\\n--------------\\n\".join(retrived_texts)\n",
    "\n",
    "    user_query = f\"\"\"\n",
    "    Questions: {query}\n",
    "    Context: {processed_retrived_text}\n",
    "    Answer the question based on the context provided.\n",
    "    \"\"\"\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    You are a helpful assistant that answers questions based on the provided context.\n",
    "    If the context does not provide enough information, you should say \"I don't know\".\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm_client.chat.completions.create(\n",
    "        model=\"deepseek/deepseek-r1:free\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_query},\n",
    "        ],\n",
    "        extra_body={\"include_reasoning\": True},\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    first_content_chunk = True\n",
    "    reasoning_dur = 0\n",
    "    final_answer_dur = 0\n",
    "    start = time.time()\n",
    "    for chunk in response:\n",
    "        if chunk.choices and getattr(chunk.choices[0].delta, \"reasoning\", None):\n",
    "            print(chunk.choices[0].delta.reasoning, end=\"\", flush=True)\n",
    "        if chunk.choices and chunk.choices[0].delta.content:\n",
    "            if first_content_chunk:\n",
    "                reasoning_dur = time.time() - start\n",
    "                print(\"\\n----------------\\n# Final answer: \", flush=True)\n",
    "                first_content_chunk = False\n",
    "            print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "            \n",
    "    print(\"\\n----------------\\n\", flush=True)\n",
    "    final_answer_dur = time.time() - start - reasoning_dur\n",
    "    print(f\"\\n# Reasoning taken: {reasoning_dur:.2f} seconds\", flush=True)\n",
    "    print(f\"\\n# Final answer taken: {final_answer_dur:.2f} seconds\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4267c927",
   "metadata": {},
   "source": [
    "## Test the RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1888074f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's see. The user is asking about file scheduling in operating systems. Hmm, but the context provided is all about disk scheduling algorithms like FCFS, SSTF, SCAN, etc. Wait, are file scheduling and disk scheduling the same thing here? Maybe the user meant disk scheduling. The context mentions Disk Scheduling Algorithms as part of Disk Storage, so it's about how the OS manages disk access requests.\n",
      "\n",
      "Looking at the context, Rank 2 lists several disk scheduling algorithms. The other ranks talk about disk access time components and examples like FCFS. There's no mention of \"file scheduling\" directly, just disk scheduling. Since the question is phrased as \"file scheduling,\" but the context doesn't address file scheduling specifically, only disk scheduling, I should check if the terms are being used interchangeably or if there's a misunderstanding. However, in standard OS terminology, disk scheduling and file scheduling aren't the same. File management would involve organization and access methods, while disk scheduling is about optimizing read/write head movements. Since the provided context doesn't mention file scheduling explicitly, and the user might have confused the terms, I should explain disk scheduling as per the context and note that file scheduling isn't covered here. Alternatively, maybe file scheduling in the context refers to how the OS handles file access requests, but the data given focuses on disk scheduling algorithms for track access. The answer should clarify that based on the context provided, disk scheduling is discussed, which manages the order of disk access requests to optimize performance.\n",
      "\n",
      "----------------\n",
      "# Final answer: \n",
      "Based on the provided context, the term \"file scheduling\" is not explicitly explained, but the documents extensively discuss **disk scheduling algorithms** in operating systems. Disk scheduling refers to the method an operating system uses to optimize the order of read/write requests to a disk drive. This is done to minimize **seek time** (movement of the read/write head to the correct track) and **rotational latency** (waiting for the desired sector to rotate under the head), thereby improving overall efficiency. \n",
      "\n",
      "Common disk scheduling algorithms mentioned in the context include:\n",
      "- **FCFS (First-Come First-Served)**\n",
      "- **SSTF (Shortest Seek Time First)**\n",
      "- **SCAN (Elevator Algorithm)**\n",
      "- **C-SCAN (Circular SCAN)**\n",
      "- **LOOK** and **C-LOOK** (optimized versions of SCAN/C-SCAN).\n",
      "\n",
      "If the question specifically refers to \"file scheduling\" (e.g., managing file access or prioritization), the context does not provide sufficient information. However, if it pertains to disk I/O operations, the answer focuses on disk scheduling algorithms.\n",
      "\n",
      "----------------\n",
      "\n",
      "\n",
      "\n",
      "# Reasoning taken: 8.45 seconds\n",
      "\n",
      "# Final answer taken: 4.58 seconds\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Basic question about the PDF content\n",
    "result1 = query_with_rag(\n",
    "    \"What is file scheduling in operating systems?\", llm_client=llm_client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b1adfb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, the user is asking about disk allocation algorithms and their trade-offs. Let me start by looking at the provided context. The context mentions different allocation methods like contiguous, linked list, indexed, and specific cases like Windows and Unix-based systems. \n",
      "\n",
      "First, contiguous allocation assigns blocks consecutively. That should be fast for access but might lead to fragmentation, right? Then linked lists use pointers, which avoids fragmentation but could have overhead from storing pointers and slower access since you have to traverse the list. \n",
      "\n",
      "Indexed allocation, especially with Unix's inodes, uses a multilevel approach. Direct blocks for small files and indirect blocks for larger ones. That offers flexibility but with added complexity. Oh, and Windows uses a file-table linked list, which is like a hybrid maybe?\n",
      "\n",
      "Wait, the user mentioned disk allocation algorithms, but some of the context refers to disk scheduling algorithms like FCFS, SSTF, SCAN, etc. But the question is about allocation, not scheduling. So I should focus on the file system allocation methods, not the disk head scheduling.\n",
      "\n",
      "So the main ones are contiguous, linked list, and indexed. Each has trade-offs: contiguous has speed vs. fragmentation; linked has no external fragmentation but sequential access overhead; indexed allows random access but has index block overhead.\n",
      "\n",
      "Additionally, Unix's inode example allows efficient handling of both small and large files, which is an advantage. Windows' file-table allocation (FAT?) uses a linked list structure but keeps part of it in the file table for faster access. Trade-offs here would be between speed and storage efficiency.\n",
      "\n",
      "Hmm, the context does not mention other methods like extents or newer techniques, so I should stick to what's provided. Also need to be careful to not confuse disk scheduling with allocation. The answer should clearly outline the three main allocation methods, their working, and their pros and cons as per the context without introducing outside knowledge.\n",
      "\n",
      "----------------\n",
      "# Final answer: \n",
      "Disk allocation algorithms determine how disk blocks are assigned to files, with each method having distinct trade-offs:\n",
      "\n",
      "1. **Contiguous Allocation**:  \n",
      "   - **How it works**: Files occupy consecutive disk blocks.  \n",
      "   - **Trade-offs**:  \n",
      "     - **Pros**: Fast sequential and direct access; minimal read/write head movement.  \n",
      "     - **Cons**: External fragmentation (unusable gaps between files); difficult to expand files.  \n",
      "\n",
      "2. **Linked List Allocation**:  \n",
      "   - **How it works**: Each block contains a pointer to the next block in the file (e.g., early FAT systems).  \n",
      "   - **Trade-offs**:  \n",
      "     - **Pros**: No external fragmentation; easy file expansion.  \n",
      "     - **Cons**: Slow random access (requires traversing pointers); storage overhead for pointers; potential unreliability if pointers are lost.  \n",
      "   - **Case Study (Windows)**: Uses a file-table allocation (FAT-like) where parts of the linked list are cached in memory for faster access.  \n",
      "\n",
      "3. **Indexed Allocation**:  \n",
      "   - **How it works**: Uses an index block (e.g., inodes in Unix) to store pointers to data blocks.  \n",
      "     - **Direct blocks** point to data.  \n",
      "     - **Indirect blocks** (single, double, triple) point to other index blocks for large files.  \n",
      "   - **Trade-offs**:  \n",
      "     - **Pros**: Efficient for both small and large files; supports random access.  \n",
      "     - **Cons**: Overhead for storing multiple levels of index blocks; complex implementation.  \n",
      "\n",
      "**Key Trade-Off Summary**:  \n",
      "- Contiguous: Speed vs. fragmentation.  \n",
      "- Linked: Flexibility vs. sequential access overhead.  \n",
      "- Indexed: Scalability vs. complexity.  \n",
      "\n",
      "The context does not elaborate on disk *scheduling* algorithms (e.g., FCFS, SCAN), which focus on read/write head movement rather than file allocation.\n",
      "----------------\n",
      "\n",
      "\n",
      "# Reasoning taken: 25.39 seconds\n",
      "\n",
      "# Final answer taken: 11.55 seconds\n"
     ]
    }
   ],
   "source": [
    "# Test 2: More complex question\n",
    "result2 = query_with_rag(\n",
    "    \"How do disk allocation algorithms work and what are their trade-offs?\",\n",
    "    llm_client=llm_client,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7a3ce6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's see. The user is asking about the methods of file management in operating systems. I need to base my answer on the provided context. \n",
      "\n",
      "Looking through the context snippets, I notice that there are mentions of \"File System Interface\" and \"File System Implementation\". Rank 2 context talks about the user's perspective (naming, structure, manipulation) and the system's perspective (storing files on disk blocks). Also, there's mention of disk management which might include allocation/deallocation, read/write operations, protection, and sharing. \n",
      "\n",
      "However, the specific methods like contiguous allocation, linked lists, file allocation tables (FAT), inode structures, or journaling aren't explicitly listed. The context provided seems to outline the high-level aspects rather than enumerating specific techniques. The answer should probably stick to what's mentioned in the context without adding outside knowledge, since the user wants the answer based solely on the provided material.\n",
      "\n",
      "So, based on Rank 2's content, the OS manages files by providing an interface for users to handle files easily without worrying about physical storage details and manages disk operations like allocation, deallocation, read/write, protection, and sharing. But the exact methods aren't detailed. The other pages (51, 43, 44) mention disk management and scheduling but don't list specific file management methods. \n",
      "\n",
      "Therefore, the answer should summarize what the context says about the OS's role in file management but note that specific methods aren't detailed here. Since the context doesn't list the actual methods like the ones mentioned earlier, maybe the correct answer according to the context is that the methods aren't specified, and the assistant should say \"I don't know\". Wait, but the user instructions say if the context doesn't provide enough info, to say \"I don't know\". But wait, the Rank 2 context says the OS manages files by providing an interface and handling storage details, allocation, etc. Maybe that's enough?\n",
      "\n",
      "Hmm. The question asks for \"Các phương pháp quản lý tệp\" which are file management methods. The context mentions aspects like allocation/deallocation, read/write, protection, sharing. Are these considered methods or just responsibilities? The system's point of view is how to store files on disk blocks, but the actual methods (like contiguous allocation, linked allocation, indexed) might not be listed. Since the exact methods aren't specified in the provided context, even though there's discussion about what the file system does, maybe the answer is \"I don't know\" because the context doesn't actually list the specific methods. Alternatively, perhaps summarizing the roles mentioned could be the answer. I need to check if the provided context gives explicit methods.\n",
      "\n",
      "Looking again at Rank 2's context: \"Manage and map files onto disk drives (e.g., allocation/deallocation, read/write, protection, sharing)\" – the example given here (allocation/deallocation, etc.) could be considered methods. However, the original question lists methodologies, which are specific techniques. The context doesn't mention specific methods like FAT or inode. So if the question is about the general methods, maybe the answer includes those aspects like allocation, management, protection. But in Vietnamese, maybe translating that into the terms like \"phương pháp cấp phát, quản lý không gian lưu trữ, bảo vệ file, chia sẻ file\". \n",
      "\n",
      "But according to the user's instruction, if the context doesn't provide enough information, should say \"I don't know\". So, does the context here have enough information? Since the context says the system's part includes managing and mapping files onto disk, handling allocation/deallocation, read/write, protection, sharing. So possibly these can be listed as the methods. But if the question expects specific algorithms or techniques like contiguous allocation, then maybe not. \n",
      "\n",
      "However, given that the context does mention these processes, it might be acceptable to outline those as the methods. Alternatively, perhaps the user is asking for the categories, but since the context doesn't explicitly list them in Vietnamese as \"phương pháp\", the safest answer would be based on what's present. \n",
      "\n",
      "So, compiling from Rank 2 context, the answer would be that the file management methods in OS include:\n",
      "\n",
      "- Providing a user-friendly interface for file operations\n",
      "- Managing storage allocation and deallocation\n",
      "- Handling read/write operations\n",
      "- Implementing file protection and sharing mechanisms\n",
      "\n",
      "But should the answer be in Vietnamese? The user question is in Vietnamese, so the answer should be in Vietnamese too. Using the context provided, translating the points. However, since the specific methods (like specific allocation strategies) aren't named, the answer may need to acknowledge that while listing the general responsibilities. But the user might need specific method names. \n",
      "\n",
      "Therefore, given that in the context, under File System Implementation and Disk Management, the specific techniques aren't listed, only the aspects of management (allocation, etc.), perhaps the correct answer according to the given context is that the methods aren't specified here, hence \"Tôi không biết\". However, the assistant might be allowed to extract the points from Rank 2's content.\n",
      "\n",
      "Wait, the user's instruction states: \"If the context does not provide enough information, you should say 'I don't know'.\" The context provided does mention aspects like allocation, deallocation, read/write, protection, sharing, but doesn't list specific techniques or methodologies. If the question is asking for the general methods, maybe these are sufficient, but if it expects specific techniques, then it's not covered. The answer in Vietnamese would depend on that. Considering the terminology in the context, the answer in Vietnamese would mention:\n",
      "\n",
      "Các phương pháp quản lý tệp trong hệ điều hành bao gồm việc cung cấp giao diện quản lý tệp cho người dùng, quản lý không gian lưu trữ (cấp phát và thu hồi), thực hiện các thao tác đọc/ghi, cùng với cơ chế bảo vệ và chia sẻ tệp. Tuy nhiên, thông tin cụ thể về các phương pháp chi tiết không được cung cấp trong ngữ cảnh này.\n",
      "\n",
      "But according to the rules, if the context doesn't provide enough info, it's better to say \"I don't know\". But in this case, the context does mention these aspects, which are part of file management. Therefore, the answer can summarize those points as methods. However, if the user's intention is to ask for specific allocation methods (like contiguous, linked list, etc.), which are not present here, the answer should be \"I don't know\". Let me check if any of the context talks about specific methods.\n",
      "\n",
      "Looking again at all the contexts provided. The highest ranked (Rank 1, page_content mentions File & Disk Management), but not specific methods. The rest talk about File System Interface, Implementation, Disk Storage, Management, and Scheduling. None of the context snippets mention specific methods like indexed allocation, etc. So based on that, perhaps the answer should list the general aspects, but note that specific techniques aren't detailed. Since the assistant is allowed to answer based on the context, and the question is about \"các phương pháp\" (methods), which in Vietnamese can be understood as the general approaches. Hence it's appropriate to list the points from Rank 2. However, to stay safe, it's better to answer that the context does not specify the exact methods, hence \"Tôi không biết\".\n",
      "\n",
      "Alternatively, since the context outlines the mechanisms that the OS uses to manage files, those can be considered as methods. Therefore, the answer would include those points. But need to ensure accuracy based on what the context provides. The answer must be in Vietnamese and derived strictly from the given context.\n",
      "\n",
      "----------------\n",
      "# Final answer: \n",
      "Dựa trên ngữ cảnh được cung cấp, các phương pháp quản lý tệp trong hệ điều hành bao gồm hai khía cạnh chính:  \n",
      "\n",
      "1. **Giao diện người dùng**: Hệ điều hành cung cấp cách đặt tên, cấu trúc và thao tác với tệp (như đọc/ghi) mà người dùng không cần quan tâm đến cấu trúc vật lý của thiết bị lưu trữ.  \n",
      "2. **Quản lý hệ thống**:  \n",
      "   - **Ánh xạ tệp vào bộ nhớ**: Quản lý cách lưu trữ tệp trên các khối đĩa (disk blocks).  \n",
      "   - **Thao tác cơ bản**: Cấp phát và thu hồi không gian lưu trữ, thực hiện đọc/ghi dữ liệu.  \n",
      "   - **Bảo mật và chia sẻ**: Cung cấp cơ chế bảo vệ tệp và quản lý việc chia sẻ tài nguyên giữa các người dùng.  \n",
      "\n",
      "Tuy nhiên, ngữ cảnh không đề cập chi tiết đến các phương pháp cụ thể (ví dụ: cấp phát liên tục, cấp phát danh sách liên kết, FAT, inode,...). Do đó, câu trả lời dựa trên thông tin hạn chế từ tài liệu được cung cấp.\n",
      "----------------\n",
      "\n",
      "\n",
      "# Reasoning taken: 50.19 seconds\n",
      "\n",
      "# Final answer taken: 9.44 seconds\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Vietnamese question (to test multilingual capabilities)\n",
    "result3 = query_with_rag(\n",
    "    \"Các phương pháp quản lý tệp trong hệ điều hành là gì?\",\n",
    "    llm_client=llm_client,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
